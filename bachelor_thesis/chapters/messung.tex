\section{Messung}
\label{sec:messung}

Zur Messung der Performance und Durchsatzrate der Implementierung betrachten wir nur den Serializer, da wir auf der Empfangsseite auf die bereit bestehenden .NET-Implementierungen der Sockets zur Datenübertragung von den UDP- bzw. TCP-Paketen setzen. Wir setzten dabei auf TCP als Übertragungsweg, da sich bei UDP die Paketgröße nicht verändern lässt bzw. auf maximal $2^{16}$ Bits (= 65.535 Bytes) beschränkt ist. Somit können wir die Paketgröße der CoAP-Nachricht, aufgrund der fehlenden Implementierung des blockweisen Transfers, nicht beliebig erhöhen. Um hier jedoch ein Szenario zu kreieren, indem wir auch sehr lange Nachrichten übermitteln können, wurde die Übertragung von CoAP-Nachrichten über TCP nach dem RFC 8323 von \citeauthor{RFC8323} implementiert.

\subsection{Nachrichtenverarbeitung}
\label{subsec:nachrichtenverarbeitung}

In diesem Szenario wird die Zeit der Nachrichtenverarbeitung auf dem Server gemessen. Dabei sieht die Messung folgenden Ablauf vor:
\begin{itemize}
    \item Die Nachrichten werden von einem Client über das jeweilige Protokoll über TCP an den CoAP-Server versendet.
    \item Dabei wird jeweils einmal eine langsame Übertragung simuliert, indem nur ein Byte alle 250 Millisekunden (4 B/s) verschickt wird, und einmal eine unveränderte Übertragung, indem man alle verfügbaren Bytes sofort versendet.
    \item Der Server hört für TCP in der asynchronen Variante auf den Port 5683 und für die synchrone Variante auf Port 5684.
    \item Dabei wird die Zeit gemessen, wie lange das Verarbeiten der Nachricht gedauert hat.
    \item Die Zeitmessung wird am Client gestartet, sobald der Client mit dem Versenden der Nachricht beginnt. Gestoppt wird diese, sobald der Server die Nachricht deserialisiert hat.
    \item Dieser Ablauf wird mehrere Male wiederholt und dann der Durchschnittswert ermittelt.
\end{itemize}

\subsubsection{BenchmarkDotnet}
\label{BenchmarkDotnet}

BenchmarkDotnet ist ein Software-Tool das vom dotnet-Team\footnote{Open-Source-Abteilung bei Microsoft für das .NET Ökosystem} entwickelt und zur Verfügung gestellt wird. Mit diesem Tool lassen sich automatisierte Laufzeittests von einem bestimmten Codeteil oder sogar einem ganzen Programm erzeugen.

BenchmarkDotnet führt dafür den ausführenden Codeteil in mehreren Durchläufen aus und misst bei jedem Durchlauf verschiedene Parameter, die vom Nutzer festgelegt werden. Dabei wird standardmäßig die durchschnittliche Laufzeit, die Fehlertoleranz und Standardabweichung ermittelt. Auch können Parameter wie allokierten Speicher, Codeverlauf (Tracer), Anzahl von Lock's (Semaphore), Anzahl verarbeiteter Aufträge im Threadpool und vieles mehr aufgezeichnet werden.

Die Ergebnisse werden dabei in verschiedene Formate exportiert. Standardmäßig werden diese in CSV, HTML und Markdown exportiert, jedoch stehen auch JSON, XML und auch als grafische Visualisierung in RPlot.

\subsection{Serialisierung und Deserialisierung}
\label{subsec:serializierung-und-deserializierung}

In diesem Szenario wird die Verarbeitungszeit der synchronen als auch asynchronen Variante der Serializierungs- bzw. Deserialisierungsmethode gemessen. Dies wird mittels der Bibliothek BenchmarkDotnet\footnote{\href{https://benchmarkdotnet.org/index.html}{https://benchmarkdotnet.org/index.html}} durchgeführt. BenchmarkDotnet ist dabei ein Tool, dass es erlaubt nativ in C\# eine vordefinierte Methode bzw. einen bestimmten Teil eines Programms einem Benchmark zu unterziehen. Somit wird ermittelt, wie sich diese beiden Varianten, unabhängig von Netzwerkgeschwindigkeit, verhalten. Dabei wird sowohl die ermittelte Durchschnittszeit als auch der Speicherverbrauch mittels BenchmarkDotnet gemessen.

Dabei können wir in BenchmarkDotnet mehrere verschiedene Durchläufe konstruieren, die sich in bestimmten Parametern unterscheiden. Um dabei die Länge der CoAP-Nachricht zu variieren, wird die Anzahl der Options und die Länge der Payload verändert. Dabei verändern sich die beiden Parameter in folgenden Schritten: 0, 1000, 100000. Somit sollten folgende Fälle abgedeckt sein:
\begin{itemize}
    \item Eine CoAP-Nachricht nur mit dem Header und dem Token.
    \item Eine CoAP-Nachricht nur mit Options und keiner Payload.
    \item Eine CoAP-Nachricht nur mit einer Payload und keinen Options.
    \item Eine CoAP-Nachricht sowohl mit Options als auch einer Payload.
\end{itemize}

Auch sollte ersichtlich sein, unter welchen Umständen synchron oder asynchron besser abschneidet.

Dabei ein Benchmark eine auszuführende Methode bzw. ein auszuführender Codeteil. Ein Benchmark wird dabei folgendermaßen deklariert:

\begin{listing}[H]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/benchmark_example.cs}
    \caption{Beispiel eines Benchmarks in BenchmarkDotnet}
    \label{listing:beispiel-eines-benchmarks-in-benchmarkdotnet}
\end{listing}

In der Main-Methode muss diese Klasse nun nur bei BenchmarkDotnet zur Ausführung registriert werden. Dies geschieht folgendermaßen:

\begin{listing}[H]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/execution_of_benchmark.cs}
    \caption{Ausführen der Benchmark-Klasse}
    \label{listing:ausfuehren-der-benchmark-klasse}
\end{listing}

\subsubsection{Nachrichtengenerierung für Benchmark}
\label{subsubsec:nachrichtengenerierung-fuer-benchmark}

Die CoAP-Nachrichten, die für den Benchmark benutzt werden, folgen folgendes Schema (x = Anzahl der Options; y = Länge der Payload in Bytes):
\begin{itemize}
    \item Die CoAP-Version ist immer auf 1.
    \item Der Typ der Nachricht ist immer Acknowledgement.
    \item Die Tokenlänge ist bei acht Bytes und wird zufällig generiert.
    \item Der Code ist CREATED (2.01).
    \item Die MessageId wird zufällig generiert.
    \item Es werden x-mal Options vom Typ UriPath erstellt.
    \item Die Payload zufällig generiert und ist y Bytes lang.
\end{itemize}

Diese wird für jeden Durchgang neu generiert und jedem einzelnen Benchmark übergeben.

\subsection{Messaufbau}
\label{subsec:messaufbau}

Die Messungen werden auf einem Rechner mit AMD Ryzen 5 2600 (6 Kerne und 12 Threads) als CPU und mit einem Arbeitsspeicher von 16 GB durchgeführt.

Die Netzwerkübertragung findet lokal statt - sprich über die Adresse 127.0.0.1 (Loopback / localhost). Mit dem Kommandozeilenbefehl \mintinline{bash}{start /affinity 1 Server.exe} wird der Server nur auf einem einzelnen Kern ausgeführt, damit nur die reine Leistung des Servers betrachtet wird und nicht durch das Scheduling des Rechners bzw. der CPU verfälscht wird.

Für das Szenario der Serialisierung und Deserialisierung werden keine speziellen Einstellungen vorgenommen, da hier die Standardeinstellungen von BenchmarkDotnet verwendet werden.

\subsection{Messergebnisse (Nachrichtenübertragung)}
\label{subsec:messergebnisse-nachrichtenuebertragung}

Für die Nachrichtenübertragung wurde die Anzahl der Options auf 100 und die Größe der Payload auf 100000 limitiert. Größere Werte haben keine bemerkenswerte Erkenntnis gebracht und wurde zwecks Übersichtlichkeit weggelassen.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T10:17:31.0524370+01:00 & 2021-11-11T10:19:16.5499204+01:00 & 00:01:45.4974834 \\
    2021-11-11T10:22:12.9707397+01:00 & 2021-11-11T10:23:58.8623836+01:00 & 00:01:45.8916439 \\
    2021-11-11T10:28:32.5175832+01:00 & 2021-11-11T10:30:18.3405198+01:00 & 00:01:45.8229366 \\
    2021-11-11T10:32:01.7660773+01:00 & 2021-11-11T10:33:47.4505300+01:00 & 00:01:45.6844527 \\
    2021-11-11T10:35:34.7139187+01:00 & 2021-11-11T10:37:20.3576467+01:00 & 00:01:45.6437280 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Asynchrone Übertragung mit 100 Options und mit einer Payload von 100 Bytes.}
    \label{tab:asynchrone-uebertragung-100-100}
\end{table}

Berechnet man nun die durchschnittliche Laufzeit aus den Ergebnissen in Tabelle \ref{tab:asynchrone-uebertragung-100-100}, in der eine CoAP-Nachricht mit 100 Options und einer Payload von 100 Bytes übermittelt wurde, mittels folgender Formel. Diese Formel wird auch für die nachfolgenden Messungen verwendet, um deren durchschnittliche Laufzeit zu ermitteln.
\begin{equation}
    \begin{aligned}
        t_{durchschnitt} ={} & \frac{\textnormal{01:45.4974834}}{5} + \frac{\textnormal{01:45.8916439}}{5} + \frac{\textnormal{01:45.8229366}}{5} + \\
        & + \frac{\textnormal{01:45.6844527}}{5} + \frac{\textnormal{01:45.6437280}}{5} = 105,71 \textnormal{Sekunden}
    \end{aligned}
\end{equation}

Daraus ergibt sich für die asynchrone Übertragung eine durchschnittliche Laufzeit von 105,71 Sekunden. Wird diese nun auch für die Messdaten in Tabelle \ref{tab:synchrone-uebertragung-100-100} berechnet, ergibt sich hier eine durchschnittliche Laufzeit von 105,61 Sekunden.

Damit ist die synchrone Übertragung um 100 Millisekunden schneller als die asynchrone Übertragung. Durch die geringe Datenmenge von 25813 Bytes für die gesamte Nachricht ist dies nicht überraschend. Bei der synchronen Übertragung wird so lange gewartet, bis die komplette CoAP-Nachricht übertragen wurde. Im Gegensatz dazu wird bei der asynchronen Übertragung die Daten sofort verarbeitet, wenn diese verfügbar sind. Da jedoch immer nur vier Bytes pro Sekunde versendet werden, ist der Mehraufwand zum Erzeugen der asynchronen Zustandsmaschine zu groß und damit unvorteilhaft für die Performanz.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T10:17:31.0525437+01:00 & 2021-11-11T10:19:16.0534992+01:00 & 00:01:45.0009555 \\
    2021-11-11T10:22:12.9707397+01:00 & 2021-11-11T10:23:58.8617438+01:00 & 00:01:45.8910041 \\
    2021-11-11T10:28:32.5175895+01:00 & 2021-11-11T10:30:18.3389314+01:00 & 00:01:45.8213419 \\
    2021-11-11T10:32:01.7660713+01:00 & 2021-11-11T10:33:47.4500247+01:00 & 00:01:45.6839534 \\
    2021-11-11T10:35:34.7139140+01:00 & 2021-11-11T10:37:20.3586945+01:00 & 00:01:45.6447805 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Synchrone Übertragung mit 100 Options und mit einer Payload von 100 Bytes.}
    \label{tab:synchrone-uebertragung-100-100}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T11:53:36.3360380+01:00 & 2021-11-11T11:59:17.2094861+01:00 & 00:05:40.8734481 \\
    2021-11-11T11:25:13.6291350+01:00 & 2021-11-11T11:30:54.8399509+01:00 & 00:05:41.2108159 \\
    2021-11-11T11:29:42.9196146+01:00 & 2021-11-11T11:35:24.2404882+01:00 & 00:05:41.3208736 \\
    2021-11-11T11:32:06.6750943+01:00 & 2021-11-11T11:37:47.7269970+01:00 & 00:05:41.0519027 \\
    2021-11-11T11:33:33.8796230+01:00 & 2021-11-11T11:39:14.4538810+01:00 & 00:05:40.5742580 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Asynchrone Übertragung mit 100 Options und mit einer Payload von 1000 Bytes}
    \label{tab:asynchrone-uebertragung-100-1000}
\end{table}

Entnimmt man die Messdaten aus der Tabelle \ref{tab:asynchrone-uebertragung-100-1000}, die einen Messdurchlauf für eine asynchrone Übertragung einer CoAP-Nachricht mit 100 Options und einer Payload von 1000 Bytes darstellt, ergibt sich eine durchschnittliche Laufzeit von 341,01 Sekunden.

Für eine synchrone Übertragung derselben Nachricht, Messdaten aus Tabelle \ref{tab:synchrone-uebertragung-100-1000} entnommen, ergibt sich eine durchschnittliche Laufzeit von 341,00 Sekunden. Damit beträgt der Abstand zwischen synchron und asynchron nur 10 Millisekunden.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T11:53:36.3360380+01:00 & 2021-11-11T11:59:17.2084637+01:00 & 00:05:40.8724257 \\
    2021-11-11T11:25:13.6291344+01:00 & 2021-11-11T11:30:54.8195384+01:00 & 00:05:41.1904040 \\
    2021-11-11T11:29:42.9196145+01:00 & 2021-11-11T11:35:24.2416850+01:00 & 00:05:41.3220705 \\
    2021-11-11T11:32:06.6750956+01:00 & 2021-11-11T11:37:47.7273639+01:00 & 00:05:41.0522683 \\
    2021-11-11T11:33:33.8796186+01:00 & 2021-11-11T11:39:14.4542465+01:00 & 00:05:40.5746279 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Synchrone Übertragung mit 100 Options und mit einer Payload von 1000 Bytes}
    \label{tab:synchrone-uebertragung-100-1000}
\end{table}

Erhöht man die Payload auf 10000 Bytes, ergibt sich für eine asynchrone Übertragung eine durchschnittliche Laufzeit von 2688,88 Sekunden und für eine synchrone Übertragung eine durchschnittliche Laufzeit von 2688,95 Sekunden. Die jeweiligen Daten wurden dabei von den Tabellen \ref{tab:asynchrone-uebertragung-100-10000} und \ref{tab:synchrone-uebertragung-100-10000} entnommen. Damit erhöht sich der Abstand auf 70 Millisekunden, das den Trend entspricht, dass mit steigender Payloadgröße, der Vorteil der Asynchronität tragender wird.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T11:44:51.4637384+01:00 & 2021-11-11T12:29:39.2904876+01:00 & 00:44:47.8267492 \\
    2021-11-11T11:45:48.8515388+01:00 & 2021-11-11T12:30:46.9714652+01:00 & 00:44:58.1199264 \\
    2021-11-11T11:46:46.0080509+01:00 & 2021-11-11T12:31:33.3480246+01:00 & 00:44:47.3399737 \\
    2021-11-11T11:47:52.2395272+01:00 & 2021-11-11T12:32:38.3763629+01:00 & 00:44:46.1368357 \\
    2021-11-11T11:49:06.5417421+01:00 & 2021-11-11T12:33:51.5103142+01:00 & 00:44:44.9685721 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Asynchrone Übertragung mit 100 Options und einer Payload von 10000 Bytes}
    \label{tab:asynchrone-uebertragung-100-10000}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T11:44:51.4637476+01:00 & 2021-11-11T12:29:39.6267910+01:00 & 00:44:48.1630434 \\
    2021-11-11T11:45:48.8515384+01:00 & 2021-11-11T12:30:46.9709319+01:00 & 00:44:58.1193935 \\
    2021-11-11T11:46:46.0080501+01:00 & 2021-11-11T12:31:33.3486035+01:00 & 00:44:47.3405534 \\
    2021-11-11T11:47:52.2395282+01:00 & 2021-11-11T12:32:38.3767620+01:00 & 00:44:46.1372338 \\
    2021-11-11T11:49:06.5417372+01:00 & 2021-11-11T12:33:51.5109177+01:00 & 00:44:44.9691805 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Synchrone Übertragung mit 100 Options und mit einer Payload von 10000 Bytes}
    \label{tab:synchrone-uebertragung-100-10000}
\end{table}

\subsection{Messergebnisse (Deserialisierung und Serialisierung)}
\label{subsec:messergebnisse-deserialisierung-serialisierung}

Die nachfolgenden Ergebnisse spiegeln die Ergebnisse der jeweiligen synchronen und asynchronen Deserialisierungs- und Serialisierungs-Methoden wieder. Dabei wurde BenchmarkDotnet verwendet, um diese vier Methoden zu testen.

Die angeführten Tabellen sind die Ergebnisse die durch BenchmarkDotnet ermittelt worden sind. Dabei ergibt sich folgende Legende:
\begin{itemize}
    \item Method: Der Name der zu testenden Methode.
    \item AmountOfOptions: Anzahl der Options (in diesem Fall Options des Typs UriPath).
    \item LengthOfPayload: Länge der Payload in Bytes.
    \item Mean: Arithmetisches Mittel aus allen Messungen.
    \item Error: Die Hälfte des 99,9\%-igen Konfidenzintervalls.
    \item StdDev: Die Standardabweichung aller Messungen.
    \item Gen X: Anzahl der Garbage Collector Generation X Sammlungen jede 1000 Operationen.
    \item Allocated: Größe des verwalteten (\textit{managed}) Speichers.
\end{itemize}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean     & Error     & StdDev    & Gen 0  & Allocated \\ \midrule
    SerializeAsync   & 0               & 0               & 5.695 μs & 0.0402 μs & 0.0336 μs & 0.0839 & 376 B     \\
    Serialize        & 0               & 0               & 5.094 μs & 0.1006 μs & 0.1198 μs & 0.0687 & 288 B     \\
    DeserializeAsync & 0               & 0               & 2.116 μs & 0.0406 μs & 0.0791 μs & 0.3777 & 1,584 B   \\
    Deserialize      & 0               & 0               & 1.639 μs & 0.0312 μs & 0.0347 μs & 0.3948 & 1,656 B   \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 0 Options und mit einer Payload von 0 Bytes}
    \label{tab:benchmark-0-0}
\end{table}

Ist nur der Header und der Token in der Nachricht enthalten, wie in Tabelle \ref{tab:benchmark-0-0} zusehen, dann sind sowohl asynchron als auch synchron gleichauf. Der Unterschied in der durchschnittlichen Laufzeit zwischen asynchron und synchron ist dem Overhead der asynchronen Zustandsmaschine, die vom C\#-Compiler generiert wird, geschuldet. Auch der leicht erhöhte Speicherverbrauch lässt sich darauf zurückführen.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean     & Error     & StdDev    & Gen 0  & Allocated \\ \midrule
    SerializeAsync   & 0               & 1000            & 5.914 μs & 0.0909 μs & 0.0805 μs & 0.0839 & 376 B     \\
    Serialize        & 0               & 1000            & 6.207 μs & 0.1199 μs & 0.1177 μs & 0.3128 & 1,312 B   \\
    DeserializeAsync & 0               & 1000            & 3.284 μs & 0.0636 μs & 0.0732 μs & 0.9232 & 3,824 B   \\
    Deserialize      & 0               & 1000            & 3.261 μs & 0.0631 μs & 0.0727 μs & 0.9308 & 3,864 B   \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 0 Options und mit einer Payload von 1000 Bytes}
    \label{tab:benchmark-0-1000}
\end{table}

Vergrößert man jedoch die Größe der Payload, wie in Tabelle \ref{tab:benchmark-0-1000} ersichtlich, zeigt sich, dass der Abstand geringer wird. Auch ist anzumerken, dass \textit{SerializeAsync} nun schneller ist als \textit{Serialize}. Waren es zuvor 0,6 Sekunden Unterschied zwischen \textit{Serialize} und \textit{SerializeAsync}, sind es nun 0,293 Sekunden. Bei \textit{Deserialize} und \textit{DeserializeAsync} betrug die Zeitdifferenz noch 0,477 Sekunden, verringert sich diese Differenz bei diesem Durchlauf auf 0,023 Sekunden.

Der Speicherverbrauch blieb bei \textit{SerializeAsync} unverändert, im Gegensatz zu \textit{Serialize} mit einer Zunahme des allokierten Speichers um 1024 Bytes. Bei beiden Methoden für das Serialisieren von CoAP-Nachrichten hat sich der Speicherverbrauch zwar auch erhöht, jedoch blieb der Abstand zueinander unverändert.

Eine mögliche Erklärung für den gleichbleibenden Speicherverbrauch von \textit{SerializeAsync} ist, dass dieser mittels eines \textit{Stream} arbeitet, der fortlaufend beschrieben wird. Im Gegensatz dazu verwendet \textit{Serialize} intern einen die \textit{PooledMemoryBufferWriter}-Klasse. Dieser stellt Methoden bereit, um auf einem Puffer, bestehend aus einer Menge von \mintinline{csharp}{Memory<byte>}s, zu schreiben. Dabei muss der Aufrufer nur Speicher vom \textit{PooledMemoryBufferWriter} \textit{"ausleihen"}, diesen mit den gewünschten Daten beschreiben und dem \textit{PooledMemoryBufferWriter} die Anzahl der geschriebenen Bytes mitteilen, damit die Position des \textit{PooledMemoryBufferWriter}s weitergeschoben werden kann. Dies wird im Codebeispiel \ref{listing:verwendung-des-pooled-memory-buffer-writers} veranschaulicht.

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/pooled_memory_buffer_writer_example.cs}
    \caption{Verwendung des PooledMemoryBufferWriters}
    \label{listing:verwendung-des-pooled-memory-buffer-writers}
\end{listing}

Der Nachteil des \textit{PooledMemoryBufferWriter}s ist, dass dieser seinen zur Verfügung stehenden Speicherbereich vergrößern muss, wenn die Kapazität erschöpft ist. Dabei vergrößert sich dieser so weit, damit der Puffer die zu schreibenden Daten aufnehmen kann. Auch ist der \textit{PooledMemoryBufferWriter} eine Eigenimplementierung, jedoch wurde im Laufe der Recherchen für diese Arbeit eine ähnliche Implementation von Microsoft\footnote{\href{https://docs.microsoft.com/en-us/dotnet/api/microsoft.toolkit.highperformance.buffers.memorybufferwriter-1?view=win-comm-toolkit-dotnet-7.0}{Dokumentation des MemoryBufferWriter}} gefunden, die dieses Problem möglicherweise besser handhabt, als die derzeitige Implementation. Da dies jedoch einen zu großen Aufwand darstellt, wurde darauf verzichtet.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean       & Error     & StdDev    & Gen 0   & Gen 1   & Gen 2   & Allocated \\ \midrule
    SerializeAsync   & 0               & 100000          & 8.611 μs   & 0.1519 μs & 0.1268 μs & 0.0763  & -       & -       & 376 B     \\
    Serialize        & 0               & 100000          & 84.259 μs  & 1.1186 μs & 1.0464 μs & 31.1279 & 31.1279 & 31.1279 & 100,312 B \\
    DeserializeAsync & 0               & 100000          & 57.500 μs  & 1.1007 μs & 1.2675 μs & 83.3130 & 83.3130 & 83.3130 & 264,040 B \\
    Deserialize      & 0               & 100000          & 107.972 μs & 1.3266 μs & 1.1078 μs & 83.2520 & 83.2520 & 83.2520 & 263,984 B \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 0 Options und mit einer Payload von 100000 Bytes}
    \label{tab:benchmark-0-100000}
\end{table}

Wird die Payload weiter vergrößert, in diesem Fall auf 100000 Bytes (100 kB), sieht man, dass die asynchronen Methoden deutlich schneller sind als die synchronen Methoden. Dies resultiert darin, dass bei I/O-lastigen Aufgaben, in diesem Fall das Lesen bzw. Schreiben der Payload vom bzw. auf den \mintinline{csharp}{Stream} oder dem \mintinline{csharp}{ReadonlyMemory<byte>}, die Asynchronität ihre Vorteile ausspielen kann, da eine große Menge an Daten gelesen oder geschrieben wird. Andere I/O-lastige Aufgaben sind etwa die Übertragung von Daten über das Netzwerk oder jeglicher Zugriff auf das Filesystem. Es wird dabei asynchron die Daten vom jeweiligen Stream gelesen (siehe Codebeispiel \ref{listing:asynchrones-auslesen-eines-streams-mit-ibufferwriter}) bzw. auf den jeweiligen Stream geschrieben (siehe Codebeispiel \ref{listing:asynchrones-beschreiben-eines-streams}).

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/example_read_async_stream.cs}
    \caption{Asynchrones Lesen eines Streams mittels IBufferWriters}
    \label{listing:asynchrones-auslesen-eines-streams-mit-ibufferwriter}
\end{listing}

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/example_write_async_stream.cs}
    \caption{Asynchrones Beschreiben eines Streams}
    \label{listing:asynchrones-beschreiben-eines-streams}
\end{listing}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean       & Error    & StdDev   & Gen 0     & Gen 1   & Allocated \\ \midrule
    SerializeAsync   & 1000            & 0               & 2,191.0 μs & 42.42 μs & 56.63 μs & 1316.4063 & -       & 5,383 KB  \\
    Serialize        & 1000            & 0               & 325.0 μs   & 3.36 μs  & 2.98 μs  & 39.0625   & -       & 160 KB    \\
    DeserializeAsync & 1000            & 0               & 950.3 μs   & 11.10 μs & 9.84 μs  & 122.0703  & 37.1094 & 526 KB    \\
    Deserialize      & 1000            & 0               & 645.3 μs   & 12.27 μs & 12.05 μs & 74.2188   & 24.4141 & 323 KB    \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 1000 Options und mit einer Payload von 0 Bytes, jedoch mit StreamWriter}
    \label{tab:benchmark-1000-0-streamwriter}
\end{table}

Sobald sich jedoch die Anzahl der Options erhöht, sinkt die durchschnittliche Laufzeit der asynchronen Methoden und der Abstand zu den synchronen Methoden vergrößert sich (siehe Tabelle \ref{tab:benchmark-1000-0-streamwriter}). Hierbei steigt die Laufzeit von \textit{SerializeAsync} auf 2191 Sekunden und der Speicherverbrauch auf 5,383 KB. Im Gegensatz dazu schneidet \textit{Serialize} mit 325 Sekunden und einem Speicherverbrauch von 160 KB deutlich besser ab. Da dies eine ungewöhnliche Abweichung darstellt, wurde nachgeforscht und der Grund für die Verlangsamung von \textit{SerializeAsync} gefunden: Um Options, die einen \textit{string} als Wert besitzen, auf einen Stream zu schreiben, wurde die \textit{StreamWriter}-Klasse verwendet. Diese ermöglicht es, mit einem bestimmten Zeichenkodierung auf einen \textit{Stream} zu schreiben (siehe Codebeispiel \ref{listing:asynchrones-schreiben-eines-strings-auf-einen-stream-streamwriter}).

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean     & Error    & StdDev   & Gen 0    & Gen 1   & Allocated \\ \midrule
    SerializeAsync   & 1000            & 0               & 740.2 μs & 14.14 μs & 15.72 μs & 50.7813  & -       & 211 KB    \\
    Serialize        & 1000            & 0               & 330.7 μs & 6.57 μs  & 5.82 μs  & 39.0625  & -       & 160 KB    \\
    DeserializeAsync & 1000            & 0               & 952.6 μs & 16.95 μs & 15.03 μs & 121.0938 & 40.0391 & 526 KB    \\
    Deserialize      & 1000            & 0               & 591.0 μs & 8.91 μs  & 8.33 μs  & 74.2188  & 24.4141 & 323 KB    \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 1000 Options und mit einer Payload von 0 Bytes, jedoch ohne StreamWriter.}
    \label{tab:benchmark-1000-0-ohne-streamwriter}
\end{table}

Verwendet man jedoch die angebotenen Schreibmethoden von der \textit{Stream}-Klasse, indem man zuvor den String durch die entsprechende Zeichenkodierung in \textit{bytes} umwandeln lässt (siehe Codebeispiel \ref{listing:asynchrones-schreiben-eines-strings-auf-einen-stream}), verringert sich die durchschnittliche Laufzeit und auch der Speicherverbrauch (siehe Tabelle \ref{tab:benchmark-1000-0-ohne-streamwriter}).

Eine mögliche Erklärung, warum bei der Verwendung des \textit{StreamWriter}s eine so hohe Laufzeit und Speicherverbrauch anfällt, kann leider nicht erbracht werden, da hier das Wissen des Verfassers übersteigt. Vergleicht man den Code der jeweiligen \textit{WriteAsync}-Methoden von \textit{StreamWriter}\footnote{\href{https://github.com/microsoft/referencesource/blob/master/mscorlib/system/io/streamwriter.cs}{Implementierung von StreamWriter auf GitHub}} mit der von \textit{Stream}\footnote{\href{https://github.com/microsoft/referencesource/blob/master/mscorlib/system/io/stream.cs}{Implementierung von Stream auf Github}}, kann man einige Optimierungen bei \textit{Stream} erkennen, die wahrscheinlich einen Unterschied ausmachen.

Die nachfolgenden Messungen wurden ohne die Nutzung des \textit{StreamWriter}s durchgeführt. Dies resultierte darin, dass die durchschnittliche Laufzeit von \textit{SerializeAsync} sich auf einem niedrigeren Niveau eingependelt hat, im Vergleich zu den Messungen, in denen noch der \textit{StreamWriter} verwendet wurde.

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/async_write_using_stream_writer.cs}
    \caption{Asynchrones Schreiben eines strings auf einen Stream mittels StreamWriter}
    \label{listing:asynchrones-schreiben-eines-strings-auf-einen-stream-streamwriter}
\end{listing}

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/async_write_using_stream.cs}
    \caption{Asynchrones Schreiben eines strings auf einen Stream}
    \label{listing:asynchrones-schreiben-eines-strings-auf-einen-stream}
\end{listing}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean     & Error    & StdDev   & Gen 0    & Gen 1   & Allocated \\ \midrule
    SerializeAsync   & 1000            & 1000            & 715.4 μs & 14.28 μs & 15.87 μs & 50.7813  & -       & 211 KB    \\
    Serialize        & 1000            & 1000            & 315.6 μs & 1.90 μs  & 1.78 μs  & 39.0625  & -       & 161 KB    \\
    DeserializeAsync & 1000            & 1000            & 923.6 μs & 6.20 μs  & 5.18 μs  & 121.0938 & 41.0156 & 529 KB    \\
    Deserialize      & 1000            & 1000            & 593.0 μs & 5.02 μs  & 4.45 μs  & 75.1953  & 15.6250 & 326 KB    \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 1000 Options und mit einer Payload von 1000 Bytes}
    \label{tab:benchmark-1000-1000}
\end{table}

Ab dem Zeitpunkt, in dem sich eine größere Anzahl an Options in der CoAP-Nachricht befinden, können die asynchronen Methoden ihren Geschwindigkeitsvorteil vom Szenario, in dem nur eine Payload mit weniger als 100000 Bytes (100 KB) gegeben war (siehe Tabellen \ref{tab:benchmark-0-0}, \ref{tab:benchmark-0-1000} und \ref{tab:benchmark-0-100000}), nicht mehr ausspielen. Dies ist darauf zurückzuführen, dass bei kleineren Datenmengen der Overhead, der durch die asynchrone Zustandsmaschine erzeugt wird, zu stark überwiegt. Deshalb werden auf die Ergebnisse, visualisiert durch die Tabellen \ref{tab:benchmark-1000-100000} bis \ref{tab:benchmark-100000-100000}, nicht näher eingegangen.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean       & Error    & StdDev   & Gen 0    & Gen 1   & Gen 2   & Allocated \\ \midrule
    SerializeAsync   & 1000            & 100000          & 721.9 μs   & 13.99 μs & 24.86 μs & 50.7813  & -       & -       & 211 KB    \\
    Serialize        & 1000            & 100000          & 368.6 μs   & 6.78 μs  & 6.34 μs  & 64.4531  & 32.2266 & 32.2266 & 258 KB    \\
    DeserializeAsync & 1000            & 100000          & 1,047.4 μs & 13.92 μs & 12.34 μs & 164.0625 & 82.0313 & 82.0313 & 783 KB    \\
    Deserialize      & 1000            & 100000          & 767.0 μs   & 15.31 μs & 16.38 μs & 83.0078  & 83.0078 & 83.0078 & 580 KB    \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 1000 Options und mit einer Payload von 100000 Bytes}
    \label{tab:benchmark-1000-100000}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean      & Error    & StdDev   & Gen 0     & Gen 1     & Gen 2     & Allocated \\ \midrule
    SerializeAsync   & 100000          & 0               & 68.01 ms  & 0.651 ms & 0.609 ms & 5125.0000 & -         & -         & 21 MB     \\
    Serialize        & 100000          & 0               & 30.87 ms  & 0.320 ms & 0.283 ms & 3843.7500 & 31.2500   & 31.2500   & 16 MB     \\
    DeserializeAsync & 100000          & 0               & 144.43 ms & 2.678 ms & 2.505 ms & 8500.0000 & 3250.0000 & 1000.0000 & 50 MB     \\
    Deserialize      & 100000          & 0               & 116.40 ms & 2.222 ms & 5.281 ms & 5400.0000 & 2000.0000 & 800.0000  & 32 MB     \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 100000 Options und mit einer Payload von 0 Bytes}
    \label{tab:benchmark-100000-0}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean      & Error    & StdDev   & Gen 0     & Gen 1     & Gen 2     & Allocated \\ \midrule
    SerializeAsync   & 100000          & 1000            & 69.35 ms  & 0.878 ms & 0.778 ms & 5125.0000 & -         & -         & 21 MB     \\
    Serialize        & 100000          & 1000            & 31.50 ms  & 0.406 ms & 0.339 ms & 3843.7500 & 31.2500   & 31.2500   & 16 MB     \\
    DeserializeAsync & 100000          & 1000            & 152.99 ms & 3.035 ms & 7.154 ms & 8500.0000 & 3250.0000 & 1000.0000 & 50 MB     \\
    Deserialize      & 100000          & 1000            & 110.34 ms & 2.188 ms & 4.320 ms & 5800.0000 & 2400.0000 & 1000.0000 & 32 MB     \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 100000 Options und 1000 Bytes}
    \label{tab:benchmark-100000-1000}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean      & Error    & StdDev    & Gen 0     & Gen 1     & Gen 2     & Allocated \\ \midrule
    SerializeAsync   & 100000          & 100000          & 69.25 ms  & 0.458 ms & 0.383 ms  & 5125.0000 & -         & -         & 21 MB     \\
    Serialize        & 100000          & 100000          & 32.23 ms  & 0.619 ms & 0.826 ms  & 3843.7500 & 31.2500   & 31.2500   & 16 MB     \\
    DeserializeAsync & 100000          & 100000          & 166.15 ms & 4.591 ms & 13.391 ms & 8750.0000 & 3250.0000 & 1000.0000 & 50 MB     \\
    Deserialize      & 100000          & 100000          & 113.15 ms & 2.256 ms & 6.545 ms  & 5400.0000 & 2000.0000 & 800.0000  & 32 MB     \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 100000 Options und mit einer Payload von 100000 Bytes (100 KB)}
    \label{tab:benchmark-100000-100000}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean      & Error    & StdDev   & Gen 0     & Gen 1     & Gen 2    & Allocated \\ \midrule
    SerializeAsync   & 100000          & 1000000         & 69.00 ms  & 1.069 ms & 0.948 ms & 5125.0000 & -         & -        & 21 MB     \\
    Serialize        & 100000          & 1000000         & 34.34 ms  & 0.407 ms & 0.361 ms & 4062.5000 & 250.0000  & 250.0000 & 19 MB     \\
    DeserializeAsync & 100000          & 1000000         & 140.89 ms & 1.490 ms & 1.394 ms & 8500.0000 & 3250.0000 & 750.0000 & 52 MB     \\
    Deserialize      & 100000          & 1000000         & 102.68 ms & 2.028 ms & 2.082 ms & 5400.0000 & 2000.0000 & 800.0000 & 34 MB     \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 100000 Options und mit einer Payload von 1000000 Bytes (100 MB)}
    \label{tab:benchmark-100000-1000000}
\end{table}

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lllllllll@{}}
    \toprule
    Method           & AmountOfOptions & LengthOfPayload & Mean       & Error    & StdDev   & Gen 0     & Gen 1     & Allocated \\ \midrule
    SerializeAsync   & 100000          & 1000000000      & 158.1 ms   & 3.13 ms  & 5.06 ms  & 5000.0000 & -         & 21 MB     \\
    Serialize        & 100000          & 1000000000      & 1,112.3 ms & 21.24 ms & 25.29 ms & 3000.0000 & -         & 3,016 MB  \\
    DeserializeAsync & 100000          & 1000000000      & 1,507.7 ms & 28.40 ms & 29.16 ms & 7000.0000 & 2000.0000 & 4,003 MB  \\
    Deserialize      & 100000          & 1000000000      & 1,764.1 ms & 34.93 ms & 52.28 ms & 4000.0000 & 1000.0000 & 2,893 MB  \\ \bottomrule
    \end{tabular}%
    }
    \caption{Benchmark mit 100000 Options und mit einer Payload von 1000000000 Bytes (1 GB)}
    \label{tab:benchmark-100000-1000000000}
\end{table}

Vergrößert man jedoch die Größe der Payload über 100 MB (in Tabelle \ref{tab:benchmark-100000-1000000000} auf 1 GB), wird der Abstand zwischen \textit{Serialize} und \textit{SerializeAsync} sowohl im Hinblick auf die durchschnittliche Laufzeit als auch den Speicherverbrauch deutlich größer. Hierbei ist \textit{SerializeAsync} um den Faktor 7 schneller im Durchschnitt und um den Faktor 143 effizienter im Speicherverbrauch.