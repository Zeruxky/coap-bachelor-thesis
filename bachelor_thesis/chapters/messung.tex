\section{Messung}
\label{sec:messung}

Zur Messung der Performance und Durchsatzrate der Implementierung betrachten wir nur den Serializer, da auf der Empfangsseite auf die bereits bestehenden .NET-Implementierungen der Sockets zur Datenübertragung von den UDP- bzw. TCP-Paketen gesetzt wird. Dabei wird auf TCP als Übertragungsweg gesetzt, da sich bei UDP die Paketgröße nicht verändern lässt bzw. auf maximal $2^{16}$ Bits (= 65.535 Bytes) beschränkt ist. Somit können wir die Paketgröße der CoAP-Nachricht, aufgrund der fehlenden Implementierung des blockweisen Transfers, nicht beliebig erhöhen. Um hier jedoch ein Szenario zu kreieren, indem wir auch sehr lange Nachrichten übermitteln können, wurde die Übertragung von CoAP-Nachrichten über TCP nach dem RFC 8323 von \citeauthor{RFC8323} \cite{RFC8323} implementiert.

\subsection{Nachrichtenverarbeitung}
\label{subsec:nachrichtenverarbeitung}

In diesem Szenario wird die Zeit der Nachrichtenverarbeitung auf dem Server gemessen. Dabei sieht die Messung folgenden Ablauf vor:
\begin{itemize}
    \item Die Nachrichten werden von einem Client über das jeweilige Protokoll über TCP an den CoAP-Server versendet.
    \item Dabei wird eine langsame Übertragung simuliert, indem nur ein Byte alle 250 Millisekunden (4 B/s) verschickt wird.
    \item Der Server hört für TCP in der asynchronen Variante auf den Port 5683 und für die synchrone Variante auf Port 5684.
    \item Dabei wird die Zeit gemessen, wie lange das Verarbeiten der Nachricht gedauert hat.
    \item Die Zeitmessung wird am Client gestartet, sobald der Client mit dem Versenden der Nachricht beginnt. Gestoppt wird diese, sobald der Server die Nachricht deserialisiert hat.
    \item Dieser Ablauf wird mehrere Male wiederholt und dann der Durchschnittswert ermittelt.
\end{itemize}

\subsubsection{BenchmarkDotnet}
\label{BenchmarkDotnet}

BenchmarkDotnet ist ein Software-Tool das vom dotnet-Team\footnote{Open-Source-Abteilung bei Microsoft für das .NET Ökosystem} entwickelt und zur Verfügung gestellt wird. Mit diesem Tool lassen sich automatisierte Laufzeittests von einem bestimmten Codeteil oder sogar einem ganzen Programm erzeugen.

BenchmarkDotnet führt dafür den ausführenden Codeteil in mehreren Durchläufen aus und misst bei jedem Durchlauf verschiedene Parameter, die vom Nutzer festgelegt werden. Dabei wird standardmäßig die durchschnittliche Laufzeit, die Fehlertoleranz und Standardabweichung ermittelt. Auch können Parameter wie allokierten Speicher, Codeverlauf (Tracer), Anzahl von Lock's (Semaphore), Anzahl verarbeiteter Aufträge im Threadpool und vieles mehr aufgezeichnet werden.

Die Ergebnisse werden dabei in verschiedene Formate exportiert. Standardmäßig werden diese in CSV, HTML und Markdown exportiert, jedoch stehen auch JSON, XML und auch als grafische Visualisierung in RPlot.

\subsection{Serialisierung und Deserialisierung}
\label{subsec:serializierung-und-deserializierung}

In diesem Szenario wird die Verarbeitungszeit der synchronen als auch asynchronen Variante der Serializierungs- bzw. Deserialisierungsmethode gemessen. Dies wird mittels der Bibliothek BenchmarkDotnet\footnote{\href{https://benchmarkdotnet.org/index.html}{https://benchmarkdotnet.org/index.html}} durchgeführt. BenchmarkDotnet ist dabei ein Tool, dass es erlaubt nativ in C\# eine vordefinierte Methode bzw. einen bestimmten Teil eines Programms einem Benchmark zu unterziehen. Somit wird ermittelt, wie sich diese beiden Varianten, unabhängig von Netzwerkgeschwindigkeit, verhalten. Dabei wird sowohl die ermittelte Durchschnittszeit als auch der Speicherverbrauch mittels BenchmarkDotnet gemessen.

Dabei können wir in BenchmarkDotnet mehrere verschiedene Durchläufe konstruieren, die sich in bestimmten Parametern unterscheiden. Um dabei die Länge der CoAP-Nachricht zu variieren, wird die Anzahl der Options und die Länge der Payload verändert. Dabei verändern sich die beiden Parameter in folgenden Schritten: 0, 1024, 4096, 65536, 131072. Somit sollten folgende Fälle abgedeckt sein:
\begin{itemize}
    \item Eine CoAP-Nachricht nur mit dem Header und dem Token.
    \item Eine CoAP-Nachricht nur mit Options und keiner Payload.
    \item Eine CoAP-Nachricht nur mit einer Payload und keinen Options.
    \item Eine CoAP-Nachricht sowohl mit Options als auch einer Payload.
\end{itemize}

Auch sollte ersichtlich sein, unter welchen Umständen synchron oder asynchron besser abschneidet.

Dabei entspricht ein Benchmark eine auszuführende Methode bzw. ein auszuführender Codeteil. Ein Benchmark wird dabei folgendermaßen deklariert: 

\begin{listing}[H]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/benchmark_example.cs}
    \caption{Beispiel eines Benchmarks in BenchmarkDotnet}
    \label{listing:beispiel-eines-benchmarks-in-benchmarkdotnet}
\end{listing}

In der Main-Methode muss diese Klasse nun nur bei BenchmarkDotnet zur Ausführung registriert werden. Dies geschieht folgendermaßen:

\begin{listing}[H]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/execution_of_benchmark.cs}
    \caption{Ausführen der Benchmark-Klasse}
    \label{listing:ausfuehren-der-benchmark-klasse}
\end{listing}

\subsubsection{Nachrichtengenerierung für Benchmark}
\label{subsubsec:nachrichtengenerierung-fuer-benchmark}

Die CoAP-Nachrichten, die für den Benchmark benutzt werden, folgen folgendem Schema (x = Anzahl der Options; y = Länge der Payload in Bytes):
\begin{itemize}
    \item Die CoAP-Version ist immer auf 1.
    \item Der Typ der Nachricht ist immer Acknowledgement.
    \item Die Tokenlänge ist bei acht Bytes und wird zufällig generiert.
    \item Der Code ist CREATED (2.01).
    \item Die MessageId wird zufällig generiert.
    \item Es werden x-mal Optionen vom Typ UriPath erstellt.
    \item Die Payload wird zufällig generiert und ist y Bytes lang.
\end{itemize}

Diese Nachrichten werden für jeden Durchgang neu generiert und jedem einzelnen Benchmark übergeben.

\subsection{Messaufbau}
\label{subsec:messaufbau}

Die Messungen werden auf einem Rechner mit AMD Ryzen 5 2600 (6 Kerne und 12 Threads) als CPU und mit einem Arbeitsspeicher von 16 GB durchgeführt.

Die Netzwerkübertragung findet lokal statt - sprich über die Adresse 127.0.0.1 (Loopback / localhost). Mit dem Kommandozeilenbefehl \mintinline{bash}{start /affinity 1 Server.exe} wird der Server nur auf einem einzelnen Kern ausgeführt, damit nur die reine Leistung des Servers betrachtet wird und nicht durch das Scheduling des Rechners bzw. der CPU verfälscht wird.

Für das Szenario der Serialisierung und Deserialisierung werden keine speziellen Einstellungen vorgenommen, da hier die Standardeinstellungen von BenchmarkDotnet verwendet werden.

\subsection{Messergebnisse (Nachrichtenübertragung)}
\label{subsec:messergebnisse-nachrichtenuebertragung}

Für die Nachrichtenübertragung wurde die Anzahl der Optionen auf 100 und die Größe der Payload auf 100000 limitiert. Größere Werte haben keine bemerkenswerte Erkenntnis gebracht und wurde zwecks Übersichtlichkeit weggelassen.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T10:17:31.0524370+01:00 & 2021-11-11T10:19:16.5499204+01:00 & 00:01:45.4974834 \\
    2021-11-11T10:22:12.9707397+01:00 & 2021-11-11T10:23:58.8623836+01:00 & 00:01:45.8916439 \\
    2021-11-11T10:28:32.5175832+01:00 & 2021-11-11T10:30:18.3405198+01:00 & 00:01:45.8229366 \\
    2021-11-11T10:32:01.7660773+01:00 & 2021-11-11T10:33:47.4505300+01:00 & 00:01:45.6844527 \\
    2021-11-11T10:35:34.7139187+01:00 & 2021-11-11T10:37:20.3576467+01:00 & 00:01:45.6437280 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Asynchrone Übertragung mit 100 Options und mit einer Payload von 100 Bytes.}
    \label{tab:asynchrone-uebertragung-100-100}
\end{table}

Berechnet man nun die durchschnittliche Laufzeit aus den Ergebnissen in Tabelle \ref{tab:asynchrone-uebertragung-100-100}, in der eine CoAP-Nachricht mit 100 Options und einer Payload von 100 Bytes übermittelt wurde, mittels folgender Formel. Diese Formel wird auch für die nachfolgenden Messungen verwendet, um deren durchschnittliche Laufzeit zu ermitteln.
\begin{equation}
    \begin{aligned}
        t_{durchschnitt} ={} & \frac{\textnormal{01:45.4974834}}{5} + \frac{\textnormal{01:45.8916439}}{5} + \frac{\textnormal{01:45.8229366}}{5} + \\
        & + \frac{\textnormal{01:45.6844527}}{5} + \frac{\textnormal{01:45.6437280}}{5} = 105,71 \textnormal{Sekunden}
    \end{aligned}
\end{equation}

Daraus ergibt sich für die asynchrone Übertragung eine durchschnittliche Laufzeit von 105,71 Sekunden. Wird diese nun auch für die Messdaten in Tabelle \ref{tab:synchrone-uebertragung-100-100} berechnet, ergibt sich hier eine durchschnittliche Laufzeit von 105,61 Sekunden.

Damit ist die synchrone Übertragung um 100 Millisekunden schneller als die asynchrone Übertragung. Durch die geringe Datenmenge von 25813 Bytes für die gesamte Nachricht ist dies nicht überraschend. Bei der synchronen Übertragung wird so lange gewartet, bis die komplette CoAP-Nachricht übertragen wurde. Im Gegensatz dazu wird bei der asynchronen Übertragung die Daten sofort verarbeitet, wenn diese verfügbar sind. Da jedoch immer nur vier Bytes pro Sekunde versendet werden, ist der Mehraufwand zum Erzeugen der asynchronen Zustandsmaschine zu groß und damit unvorteilhaft für die Performanz.

\begin{table}[h]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Start                             & Ende                              & Laufzeit         \\ \midrule
    2021-11-11T10:17:31.0525437+01:00 & 2021-11-11T10:19:16.0534992+01:00 & 00:01:45.0009555 \\
    2021-11-11T10:22:12.9707397+01:00 & 2021-11-11T10:23:58.8617438+01:00 & 00:01:45.8910041 \\
    2021-11-11T10:28:32.5175895+01:00 & 2021-11-11T10:30:18.3389314+01:00 & 00:01:45.8213419 \\
    2021-11-11T10:32:01.7660713+01:00 & 2021-11-11T10:33:47.4500247+01:00 & 00:01:45.6839534 \\
    2021-11-11T10:35:34.7139140+01:00 & 2021-11-11T10:37:20.3586945+01:00 & 00:01:45.6447805 \\ \bottomrule
    \end{tabular}%
    }
    \caption{Synchrone Übertragung mit 100 Options und mit einer Payload von 100 Bytes.}
    \label{tab:synchrone-uebertragung-100-100}
\end{table}

Entnimmt man die Messdaten aus der Tabelle \ref{tab:asynchrone-uebertragung-100-1000}, die einen Messdurchlauf für eine asynchrone Übertragung einer CoAP-Nachricht mit 100 Options und einer Payload von 1000 Bytes darstellt, ergibt sich eine durchschnittliche Laufzeit von 341,01 Sekunden.

Für eine synchrone Übertragung derselben Nachricht, Messdaten aus Tabelle \ref{tab:synchrone-uebertragung-100-1000} entnommen, ergibt sich eine durchschnittliche Laufzeit von 341,00 Sekunden. Damit beträgt der Abstand zwischen synchron und asynchron nur 10 Millisekunden.

Erhöht man die Payload auf 10000 Bytes, ergibt sich für eine asynchrone Übertragung eine durchschnittliche Laufzeit von 2688,88 Sekunden und für eine synchrone Übertragung eine durchschnittliche Laufzeit von 2688,95 Sekunden. Die jeweiligen Daten wurden dabei von den Tabellen \ref{tab:asynchrone-uebertragung-100-10000} und \ref{tab:synchrone-uebertragung-100-10000} entnommen. Damit erhöht sich der Abstand auf 70 Millisekunden, das den Trend entspricht, dass mit steigender Payloadgröße, der Vorteil der Asynchronität tragender wird.

\subsection{Messergebnisse (Deserialisierung und Serialisierung)}
\label{subsec:messergebnisse-deserialisierung-serialisierung}

Die detaillierten Ergebnisse zu den Messungen der Deserialisierung und Serialisierung sind im Anhang aufgeführt. Nachfolgend werden nur direkte Vergleiche zwischen der synchronen und asynchronen Implementation der jeweiligen Operation vorgenommen und auf diese verwiesen. Durch das Tool BenchmarkDotnet werden die Messergebnisse, die in diesen Tabellen aufgeführt sind, ermittelt. Dabei ergibt sich folgende Legende für die Messtabellen:
\begin{itemize}
    \item $n_{Optionen}$: Anzahl der Optionen.
    \item $l_{Payload}$: Die Größe bzw. Länge der CoAP-Payload in Bytes.
    \item $t_{X}$: Die durchschnittliche Laufzeit der Methode X in \mu s.
\end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
    $n_{Optionen}$ & $l_{Payload}$ [B] & $t_{DeserializeAsync}$ [\mu s] & $t_{Deserialize}$ [\mu s] \\ \midrule
    0                   & 0                 & 2.231                          & 1.679                     \\
    0                   & 1024              & 3.298                          & 3.683                     \\
    0                   & 4096              & 5.077                          & 6.570                     \\
    0                   & 65536             & 64.490                         & 98.533                    \\
    0                   & 131072            & 111.011                        & 175.433                   \\
    1024                & 0                 & 1440.076                       & 1030.051                  \\
    1024                & 1024              & 1402.291                       & 1014.093                  \\
    1024                & 4096              & 1416.083                       & 1027.275                  \\
    1024                & 65536             & 1592.417                       & 1631.388                  \\
    1024                & 131072            & 1817.051                       & 1781.418                  \\
    4096                & 0                 & 8416.154                       & 6477.162                  \\
    4096                & 1024              & 8147.070                       & 6711.475                  \\
    4096                & 4096              & 8737.255                       & 6558.996                  \\
    4096                & 65536             & 9057.536                       & 6924.552                  \\
    4096                & 131072            & 9543.723                       & 7530.808                  \\
    65536               & 0                 & 203180.664                     & 166612.138                \\
    65536               & 1024              & 198211.164                     & 190898.380                \\
    65536               & 4096              & 201316.657                     & 190316.150                \\
    65536               & 65536             & 200257.897                     & 195944.825                \\
    65536               & 131072            & 201631.362                     & 170582.006                \\
    131072              & 0                 & 372129.381                     & 286105.657                \\
    131072              & 1024              & 372065.709                     & 285783.220                \\
    131072              & 4096              & 368936.160                     & 282355.564                \\
    131072              & 65536             & 366150.575                     & 292059.675                \\
    131072              & 131072            & 370709.611                     & 304488.343                \\ \bottomrule
    \end{tabular}%  
    \caption{Vergleich DeserializeAsync und Deserialize}
    \label{tab:vergleich-deserialize-async-deserialize}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
    $n_{Optionen}$ & $l_{Payload}$ [B] & $t_{SerializeAsync}$ [\mu s]& $t_{Serialize}$ [\mu s] \\ \midrule
    0                   & 0                     & 5.618                                           & 5.142                                      \\
    0                   & 1024                  & 5.658                                           & 5.867                                      \\
    0                   & 4096                  & 5.710                                           & 7.186                                      \\
    0                   & 65536                 & 7.356                                           & 23.527                                     \\
    0                   & 131072                & 9.347                                           & 49.680                                     \\
    1024                & 0                     & 857.681                                         & 551.922                                    \\
    1024                & 1024                  & 864.956                                         & 569.763                                    \\
    1024                & 4096                  & 874.255                                         & 570.333                                    \\
    1024                & 65536                 & 853.992                                         & 563.479                                    \\
    1024                & 131072                & 878.702                                         & 594.334                                    \\
    4096                & 0                     & 3415.820                                        & 2758.439                                   \\
    4096                & 1024                  & 3520.379                                        & 2659.178                                   \\
    4096                & 4096                  & 3415.203                                        & 2596.436                                   \\
    4096                & 65536                 & 3517.490                                        & 2507.161                                   \\
    4096                & 131072                & 3533.880                                        & 2559.126                                   \\
    65536               & 0                     & 57919.596                                       & 58896.194                                  \\
    65536               & 1024                  & 55995.639                                       & 58689.037                                  \\
    65536               & 4096                  & 54769.243                                       & 58655.719                                  \\
    65536               & 65536                 & 56494.925                                       & 59328.566                                  \\
    65536               & 131072                & 56286.964                                       & 57420.750                                  \\
    131072              & 0                     & 112894.956                                      & 117807.577                                 \\
    131072              & 1024                  & 110892.868                                      & 119120.364                                 \\
    131072              & 4096                  & 109851.123                                      & 120061.250                                 \\
    131072              & 65536                 & 111436.460                                      & 120002.202                                 \\
    131072              & 131072                & 112449.316                                      & 120453.645                                 \\ \bottomrule
    \end{tabular}%
    \caption{Vergleich SerializeAsync und Serialize}
    \label{tab:vergleich-serialize-async-serialize}
\end{table}

Wie in Tabelle \ref{tab:vergleich-deserialize-async-deserialize} ersichtlich, arbeitet die DeserializeAsync-Methode immer schneller, als ihr synchroner Gegenpart, solange keine CoAP-Optionen sich in der CoAP-Nachricht befinden. Sobald sich dies jedoch ändert, ist der Mehraufwand für den Aufbau und Verwaltung der asynchronen Zustandsmaschine nachteilig für die asynchrone Methode. Dies lässt sich dadurch erklären, dass die Größe der Optionen zu klein ist, um von der asynchronen Verarbeitung, mit ihren effizienteren Prozessen, zu profitieren.

Vergrößert man jedoch die Größe der Payload, dann profitiert der Deserialisierungsvorgang von der angebotenen Asynchronität. Obwohl sich der Unterschied in einigen 100 Mikrosekunden bewegt, kann es bei steigender Anzahl gleichzeitig eintreffender Nachrichten eine merkbare Auswirkung haben, da bei schnellerer Verarbeitung, auch schneller die nächste Nachricht abgearbeitet werden kann.

Eine mögliche Erklärung für den gleichbleibenden Speicherverbrauch von \textit{SerializeAsync} ist, dass dieser mittels eines \textit{Stream} arbeitet, der fortlaufend beschrieben wird. Im Gegensatz dazu verwendet \textit{Serialize} intern einen die \textit{PooledMemoryBufferWriter}-Klasse. Dieser stellt Methoden bereit, um auf einem Puffer, bestehend aus einer Menge von \mintinline{csharp}{Memory<byte>}s, zu schreiben. Dabei muss der Aufrufer nur Speicher vom \textit{PooledMemoryBufferWriter} \textit{"ausleihen"}, diesen mit den gewünschten Daten beschreiben und dem \textit{PooledMemoryBufferWriter} die Anzahl der geschriebenen Bytes mitteilen, damit die Position des \textit{PooledMemoryBufferWriter}s weitergeschoben werden kann. Dies wird im Codebeispiel \ref{listing:verwendung-des-pooled-memory-buffer-writers} veranschaulicht.

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/pooled_memory_buffer_writer_example.cs}
    \caption{Verwendung des PooledMemoryBufferWriters}
    \label{listing:verwendung-des-pooled-memory-buffer-writers}
\end{listing}

Der Nachteil des \textit{PooledMemoryBufferWriter}s ist, dass dieser seinen zur Verfügung stehenden Speicherbereich vergrößern muss, wenn die Kapazität erschöpft ist. Dabei vergrößert sich dieser so weit, damit der Puffer die zu schreibenden Daten aufnehmen kann. Auch ist der \textit{PooledMemoryBufferWriter} eine Eigenimplementierung, jedoch wurde im Laufe der Recherchen für diese Arbeit eine ähnliche Implementation von Microsoft\footnote{\href{https://docs.microsoft.com/en-us/dotnet/api/microsoft.toolkit.highperformance.buffers.memorybufferwriter-1?view=win-comm-toolkit-dotnet-7.0}{Dokumentation des MemoryBufferWriter}} gefunden, die dieses Problem möglicherweise besser handhabt, als die derzeitige Implementation. Da dies jedoch einen zu großen Aufwand darstellt, wurde darauf verzichtet.

Wird die Payload weiter vergrößert, in diesem Fall auf 100000 Bytes (100 kB), sieht man, dass die asynchronen Methoden deutlich schneller sind als die synchronen Methoden. Dies resultiert darin, dass bei I/O-lastigen Aufgaben, in diesem Fall das Lesen bzw. Schreiben der Payload vom bzw. auf den \mintinline{csharp}{Stream} oder dem \mintinline{csharp}{ReadonlyMemory<byte>}, die Asynchronität ihre Vorteile ausspielen kann, da eine große Menge an Daten gelesen oder geschrieben wird. Andere I/O-lastige Aufgaben sind etwa die Übertragung von Daten über das Netzwerk oder jeglicher Zugriff auf das Filesystem. Es wird dabei asynchron die Daten vom jeweiligen Stream gelesen (siehe Codebeispiel \ref{listing:asynchrones-auslesen-eines-streams-mit-ibufferwriter}) bzw. auf den jeweiligen Stream geschrieben (siehe Codebeispiel \ref{listing:asynchrones-beschreiben-eines-streams}).

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/example_read_async_stream.cs}
    \caption{Asynchrones Lesen eines Streams mittels IBufferWriters}
    \label{listing:asynchrones-auslesen-eines-streams-mit-ibufferwriter}
\end{listing}

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/example_write_async_stream.cs}
    \caption{Asynchrones Beschreiben eines Streams}
    \label{listing:asynchrones-beschreiben-eines-streams}
\end{listing}

Sobald sich jedoch die Anzahl der Options erhöht, sinkt die durchschnittliche Laufzeit der asynchronen Methoden und der Abstand zu den synchronen Methoden vergrößert sich (siehe Tabelle \ref{tab:benchmark-1000-0-streamwriter}). Hierbei steigt die Laufzeit von \textit{SerializeAsync} auf 2191 Sekunden und der Speicherverbrauch auf 5,383 KB. Im Gegensatz dazu schneidet \textit{Serialize} mit 325 Sekunden und einem Speicherverbrauch von 160 KB deutlich besser ab. Da dies eine ungewöhnliche Abweichung darstellt, wurde nachgeforscht und der Grund für die Verlangsamung von \textit{SerializeAsync} gefunden: Um Options, die einen \textit{string} als Wert besitzen, auf einen Stream zu schreiben, wurde die \textit{StreamWriter}-Klasse verwendet. Diese ermöglicht es, mit einer bestimmten Zeichenkodierung auf einen \textit{Stream} zu schreiben (siehe Codebeispiel \ref{listing:asynchrones-schreiben-eines-strings-auf-einen-stream-streamwriter}).

Verwendet man jedoch die angebotenen Schreibmethoden von der \textit{Stream}-Klasse, indem man zuvor den String durch die entsprechende Zeichenkodierung in \textit{bytes} umwandeln lässt (siehe Codebeispiel \ref{listing:asynchrones-schreiben-eines-strings-auf-einen-stream}), verringert sich die durchschnittliche Laufzeit und auch der Speicherverbrauch (siehe Tabelle \ref{tab:benchmark-1000-0-ohne-streamwriter}).

Eine mögliche Erklärung, warum bei der Verwendung des \textit{StreamWriter}s eine so hohe Laufzeit und Speicherverbrauch anfällt, kann leider nicht erbracht werden, da hier das Wissen des Verfassers übersteigt. Vergleicht man den Code der jeweiligen \textit{WriteAsync}-Methoden von \textit{StreamWriter}\footnote{\href{https://github.com/microsoft/referencesource/blob/master/mscorlib/system/io/streamwriter.cs}{Implementierung von StreamWriter auf GitHub}} mit der von \textit{Stream}\footnote{\href{https://github.com/microsoft/referencesource/blob/master/mscorlib/system/io/stream.cs}{Implementierung von Stream auf Github}}, kann man einige Optimierungen bei \textit{Stream} erkennen, die wahrscheinlich einen Unterschied ausmachen.

Die nachfolgenden Messungen wurden ohne die Nutzung des \textit{StreamWriter}s durchgeführt. Dies resultierte darin, dass die durchschnittliche Laufzeit von \textit{SerializeAsync} sich auf einem niedrigeren Niveau eingependelt hat, im Vergleich zu den Messungen, in denen noch der \textit{StreamWriter} verwendet wurde.

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/async_write_using_stream_writer.cs}
    \caption{Asynchrones Schreiben eines strings auf einen Stream mittels StreamWriter}
    \label{listing:asynchrones-schreiben-eines-strings-auf-einen-stream-streamwriter}
\end{listing}

\begin{listing}[h]
    \inputminted[framesep=2mm, baselinestretch=1.2, fontsize=\normalsize, linenos]{csharp}{codes/async_write_using_stream.cs}
    \caption{Asynchrones Schreiben eines strings auf einen Stream}
    \label{listing:asynchrones-schreiben-eines-strings-auf-einen-stream}
\end{listing}

Ab dem Zeitpunkt, in dem sich eine größere Anzahl an Options in der CoAP-Nachricht befinden, können die asynchronen Methoden ihren Geschwindigkeitsvorteil vom Szenario, in dem nur eine Payload mit weniger als 100000 Bytes (100 KB) gegeben war (siehe Tabellen \ref{tab:benchmark-0-0}, \ref{tab:benchmark-0-1000} und \ref{tab:benchmark-0-100000}), nicht mehr ausspielen. Dies ist darauf zurückzuführen, dass bei kleineren Datenmengen der Overhead, der durch die asynchrone Zustandsmaschine erzeugt wird, zu stark überwiegt. Deshalb werden auf die Ergebnisse, visualisiert durch die Tabellen \ref{tab:benchmark-1000-100000} bis \ref{tab:benchmark-100000-100000}, nicht näher eingegangen.

Vergrößert man jedoch die Größe der Payload über 100 MB (in Tabelle \ref{tab:benchmark-100000-1000000000} auf 1 GB), wird der Abstand zwischen \textit{Serialize} und \textit{SerializeAsync} sowohl im Hinblick auf die durchschnittliche Laufzeit als auch den Speicherverbrauch deutlich größer. Hierbei ist \textit{SerializeAsync} um den Faktor 7 schneller im Durchschnitt und um den Faktor 143 effizienter im Speicherverbrauch.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ylabel={Laufzeit [\mu s]},
            ymode=log,
            grid=both,
        ]
        \addplot[
            only marks,
        ] table[
            x expr=\coordindex,
            col sep=semicolon,
            y=Mean,
        ]
            {measurements/deserialize_result.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{Messergebnisse von Deserialize-Methode als Diagramm}
    \label{fig:messergebnisse-deserialize}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ylabel={Laufzeit [\mu s]},
            ymode=log,
            grid=both,
        ]
        \addplot[
            only marks,
        ] table[
            x expr=\coordindex,
            col sep=semicolon,
            y=Mean,
        ]
            {measurements/deserialize_async_result.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{Messergebnisse von DeserializeAsync-Methode als Diagramm}
    \label{fig:messergebnisse-deserialize-async}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ylabel={Laufzeit [\mu s]},
            ymode=log,
            grid=both,
        ]
        \addplot[
            only marks,
        ] table[
            x expr=\coordindex,
            col sep=semicolon,
            y=Mean,
        ]
            {measurements/serialize_async_result.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{Messergebnisse von SerializeAsync-Methode als Diagramm}
    \label{fig:messergebnisse-serialize-async}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ylabel={Laufzeit [\mu s]},
            ymode=log,
            grid=both,
        ]
        \addplot[
            only marks,
        ] table[
            x expr=\coordindex,
            col sep=semicolon,
            y=Mean,
        ]
            {measurements/serialize_result.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{Messergebnisse von Serialize-Methode als Diagramm}
    \label{fig:messergebnisse-serialize}
\end{figure}